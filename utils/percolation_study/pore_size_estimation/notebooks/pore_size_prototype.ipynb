{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pore estimation with clustering and non-convex hull "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pore cloud points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all check point values and sort them\n",
    "\n",
    "# File info: \n",
    "#filedir = \"/Users/ada/Documents/Code_Development_2020/rhombi/percolations_study/vsc3/percolation_runs/copy_dir\"\n",
    "#filedir_TU = \"/home/carina/Documents/2D_patchy/percolation_study/vsc3/runs/runs\"\n",
    "\n",
    "#phi=0.125\n",
    "#delta=0.2\n",
    "#T=0.01 \n",
    "#ptypes= ['double_manta_asymm_1', 'double_mouse_asymm_1', 'double_mouse_symm_1', 'double_mouse_symm_2']\n",
    "#ptype = 'double_mouse_asymm_1'\n",
    "#val=17600000\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import glob\n",
    "import networkx as nx\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn-poster') \n",
    "mpl.rcParams['font.family'] = \"sans-serif\"\n",
    "sns.set_context('poster')\n",
    "from collections import defaultdict \n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    rot_mat = np.zeros((2,2))\n",
    "\n",
    "    rot_mat[0,0] = np.cos(theta) \n",
    "    rot_mat[0,1] = -np.sin(theta)\n",
    "    rot_mat[1,0] = np.sin(theta)\n",
    "    rot_mat[1,1] = np.cos(theta)\n",
    "\n",
    "    return rot_mat\n",
    "\n",
    "\n",
    "def get_orient(v, rot_mat):\n",
    "    return rot_mat.dot(v)\n",
    "\n",
    "def read_bonds(filen):\n",
    "    first_line_pair = [0,0,0,0]\n",
    "    cut=False\n",
    "    with open(filen, 'r') as f:\n",
    "        network_list = []\n",
    "        for line in f:\n",
    "            if \"#\" in line:\n",
    "                network_list.append([])\n",
    "                first_line_pair = [0,0,0,0]\n",
    "                cut=False\n",
    "\n",
    "            else:\n",
    "                line_counter=len(network_list[-1])\n",
    "                pairs = list(map(int, line.split(\" \")))\n",
    "                if pairs == first_line_pair or cut==True:\n",
    "                    cut=True\n",
    "                else:\n",
    "                    network_list[-1].append(np.array(pairs))\n",
    "\n",
    "                if line_counter == 0:\n",
    "                    first_line_pair = pairs\n",
    "    network_list = [ np.array(item) for item in network_list]\n",
    "\n",
    "    return network_list\n",
    "\n",
    "\n",
    "def read_config(fdir, val):\n",
    "    pos_i = np.fromfile(\"{}/positions_{}.bin\".format(fdir, val))\n",
    "    pos_i = np.reshape(pos_i, (-1,3))\n",
    "    pos_i = pos_i[:,:2]\n",
    "\n",
    "    orient_i = np.fromfile(\"{}/orientations_{}.bin\".format(fdir, val))\n",
    "    orient_i = np.reshape(orient_i, (-1,5))[:,4]\n",
    "\n",
    "\n",
    "    return pos_i, orient_i\n",
    "\n",
    "def get_rhombi_vertices(pos_i,orient_i,i):\n",
    "\n",
    "    def get_edge_points(pos_i,ax_n,sign_p):\n",
    "        vertex_n = np.zeros(2)\n",
    "        vertex_n = pos_i + sign_p[0]*ax_n[:,0]/2. + sign_p[1]*ax_n[:,1]/2.\n",
    "        return vertex_n\n",
    "\n",
    "    sin60 = np.sin(np.pi/3.)\n",
    "    cos60 = np.cos(np.pi/3.)\n",
    "\n",
    "    ax0 = np.array([[1,cos60],[0,sin60]])\n",
    "    vertices = np.zeros((4,2))\n",
    "    ax_n = np.zeros((2,2))\n",
    "\n",
    "    rotmat_i = rotation_matrix(orient_i[i])\n",
    "    ax_n = get_orient(ax0, rotmat_i)\n",
    "\n",
    "    vertices[0] = get_edge_points(pos_i[i],ax_n,np.array([-1,-1]))\n",
    "    vertices[1] = get_edge_points(pos_i[i],ax_n,np.array([+1,-1]))\n",
    "    vertices[2] = get_edge_points(pos_i[i],ax_n,np.array([+1,+1]))\n",
    "    vertices[3] = get_edge_points(pos_i[i],ax_n,np.array([-1,+1]))\n",
    "\n",
    "    return vertices\n",
    "\n",
    "def get_intersect(pos_i,all_vertices,id_i,sx,sy,r_sphere,a_rhombi,cut_off):\n",
    "\n",
    "    intersect=False \n",
    "    dist  = pos_i[id_i] - np.array([sx,sy])\n",
    "    dist = dist - np.array([box_lx,box_ly])*np.rint(\n",
    "        dist/np.array([box_lx,box_ly]))\n",
    "\n",
    "    # test outer sphere of rhombi as coarse overlap test\n",
    "    if np.abs(np.linalg.norm(dist))>cut_off:\n",
    "        intersect=False \n",
    "\n",
    "    else:\n",
    "\n",
    "        nearest_point = np.array([sx,sy]) + (dist/np.linalg.norm(dist))*r_sphere \n",
    "        ndist = pos_i[id_i] - nearest_point\n",
    "        ndist = ndist - np.array([box_lx,box_ly])*np.rint(\n",
    "        dist/np.array([box_lx,box_ly]))\n",
    "\n",
    "        e01 = (all_vertices[id_i][1] - all_vertices[id_i][0])/a_rhombi\n",
    "        e02 = (all_vertices[id_i][3] - all_vertices[id_i][0])/a_rhombi\n",
    "\n",
    "        nearest_point_rhs = np.array([np.dot(ndist,e01),\n",
    "            np.dot(ndist,e02)])\n",
    "\n",
    "        length_nearest_point_rhs = np.linalg.norm(nearest_point_rhs)\n",
    "\n",
    "        if length_nearest_point_rhs < 1:\n",
    "            intersect=True\n",
    "\n",
    "    return intersect \n",
    "\n",
    "\n",
    "def make_cell_list(r_sphere,rhombi_long_diagonal,box_lx):\n",
    "    L_cell_min = r_sphere + (rhombi_long_diagonal/2)\n",
    "        \n",
    "    Nx_cell = int(np.floor(box_lx/L_cell_min))\n",
    "    Ny_cell = Nx_cell\n",
    "\n",
    "    L_cell_x = box_lx/Nx_cell\n",
    "    L_cell_y = L_cell_x\n",
    "\n",
    "    cell_ID_of_particle_x = np.floor(pos_i[:,0]/L_cell_x).astype(int)\n",
    "    cell_ID_of_particle_y = np.floor(pos_i[:,1]/L_cell_y).astype(int)\n",
    "    cell_ID_of_particle = np.column_stack((cell_ID_of_particle_x,cell_ID_of_particle_y))\n",
    "\n",
    "    cell_list=defaultdict(list)\n",
    "\n",
    "    # fill cell list\n",
    "    for i, entry in enumerate(cell_ID_of_particle):\n",
    "        cell_list[(entry[0],entry[1])].append(i)\n",
    "\n",
    "    return cell_list, L_cell_x,L_cell_y, Nx_cell, Ny_cell \n",
    "\n",
    "def read_config():\n",
    "    box_all = np.fromfile(\"Box.bin\")\n",
    "    box_x_center = box_all[0]  \n",
    "    box_y_center = box_all[1]    \n",
    "\n",
    "    box_lx = box_all[3]\n",
    "    box_ly = box_all[4]\n",
    "\n",
    "    pos_i = np.fromfile(\"positions.bin\")\n",
    "    pos_i = np.reshape(pos_i, (-1,3))\n",
    "    pos_i = pos_i[:,:2]\n",
    "\n",
    "    orient_i = np.fromfile(\"orientations.bin\")\n",
    "    orient_i = np.reshape(orient_i, (-1,5))[:,4]\n",
    "\n",
    "    return box_x_center, box_y_center, box_lx,box_ly,pos_i,orient_i \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # read config \n",
    "    \n",
    "    box_x_center, box_y_center, box_lx,box_ly,pos_i,orient_i  = read_config()\n",
    "    \n",
    "    N_particles = len(pos_i)\n",
    "    N_vertices = []\n",
    "\n",
    "    # define parameters \n",
    "    r_sphere=0.2\n",
    "    a_rhombi = 1.0\n",
    "    alpha = np.pi/3\n",
    "    rhombi_long_diagonal = a_rhombi * np.sqrt(np.power(1+np.cos(alpha)+np.sin(alpha),2))\n",
    "\n",
    "    Nsteps = 1000000\n",
    "    pore_cloud_centers = []\n",
    "\n",
    "    box_xstart = box_x_center - box_lx/2.\n",
    "    box_xend = box_x_center + box_lx/2\n",
    "\n",
    "    box_ystart = box_y_center - box_ly/2.\n",
    "    box_yend = box_y_center + box_ly/2. \n",
    "\n",
    "    np.random.seed(10)\n",
    "   \n",
    "    overlap_candidates=[]\n",
    "    sx=0\n",
    "    sy=0\n",
    "    step_size = 0.2 \n",
    "    \n",
    "    accepted_move = False \n",
    "\n",
    "    # get vertices from particle centers \n",
    "    all_vertices = []\n",
    "    for i in range(N_particles):\n",
    "        all_vertices.append(get_rhombi_vertices(pos_i,orient_i,i))\n",
    "    \n",
    "    # make inital cell_list\n",
    "    cell_list, L_cell_x,L_cell_y, Nx_cell, Ny_cell = make_cell_list(r_sphere,rhombi_long_diagonal,box_lx)\n",
    "    \n",
    "    for istep in range(Nsteps):\n",
    "\n",
    "        # pick center of sphere: \n",
    "        # if in previous step disk had overlap candidates, max step size is \n",
    "        if accepted_move:\n",
    "                \n",
    "                r_sphere += r_sphere + 0.1\n",
    "                sx = sx + step_size*np.random.uniform(-1,1)\n",
    "                sy = sy + step_size*np.random.uniform(-1,1)\n",
    "        \n",
    "                # TODO redo cell_list\n",
    "                # TODO \n",
    "                \n",
    "\n",
    "        else:\n",
    "            sx = np.random.uniform(box_xstart,box_xend)\n",
    "            sy = np.random.uniform(box_ystart,box_yend)\n",
    "            \n",
    "        sp=np.array([sx,sy]) \n",
    "        \n",
    "        cell_of_sphere = np.array([int(np.floor(sx/L_cell_x)),\n",
    "            int(np.floor(sy/L_cell_y))])\n",
    "\n",
    "        overlap_candidates = []\n",
    "        # add particles of original cell \n",
    "        overlap_candidates.extend(cell_list[(cell_of_sphere[0],cell_of_sphere[1])])\n",
    "\n",
    "        # get particles from neighbour cells \n",
    "        neighbour_cells = np.array([[-1,0],[1,0],[0,-1],[0,1],[-1,-1],[1,-1],[-1,1],[1,1]])\n",
    "\n",
    "        for ncell in neighbour_cells: \n",
    "            celli = cell_of_sphere + ncell\n",
    "            celli = (celli[0]%Nx_cell, celli[1]%Ny_cell)\n",
    "           \n",
    "\n",
    "            overlap_candidates.extend(cell_list[celli])\n",
    "\n",
    "        #overlap_candidates=range(N_particles)\n",
    "        global_intersect=False \n",
    "        ic=0\n",
    "        accepted_move = False\n",
    "    \n",
    "        if overlap_candidates:\n",
    "            while (global_intersect == False and ic < len(overlap_candidates)):\n",
    "                \n",
    "                id_i = overlap_candidates[ic]       \n",
    "                global_intersect=get_intersect(pos_i,all_vertices,id_i,sx,sy,r_sphere,a_rhombi,L_cell_min)\n",
    "\n",
    "                ic=ic+1 \n",
    "\n",
    "\n",
    "            if global_intersect==False:\n",
    "                pore_cloud_centers.append([sx,sy])\n",
    "                accepted_move = True \n",
    "\n",
    "        else:\n",
    "            pore_cloud_centers.append([sx,sy])\n",
    "            accpeted_move = True \n",
    "\n",
    "    print(\"Fraction of non_overlapping spheres: {}\".format(len(pore_cloud_centers)/Nsteps))\n",
    "\n",
    "    # write out file \n",
    "    arr = np.asarray(pore_cloud_centers)\n",
    "    arr.tofile(\"pore_cloud_centers.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,20))\n",
    "ax.set_aspect('equal', 'box')\n",
    "polygon_color = 'cyan'\n",
    "#polygon_color = \"#04CC80\"\n",
    "\n",
    "xcoords = range(Nx_cell)*L_cell_x\n",
    "for xc in xcoords:\n",
    "    plt.axvline(x=xc)\n",
    "ycoords = range(Ny_cell)*L_cell_y\n",
    "for xc in ycoords:\n",
    "    plt.axhline(y=xc)\n",
    "\n",
    "\n",
    "for i in range(N_particles):\n",
    "    vertices = get_rhombi_vertices(pos_i, orient_i, i)\n",
    "    polygon = patches.Polygon(vertices,\n",
    "        linewidth=0.1,\n",
    "        edgecolor='k',\n",
    "        facecolor=polygon_color, alpha=0.7)\n",
    "\n",
    "    ax.add_patch(polygon)   \n",
    "\n",
    "\n",
    "for sphere_i in pore_cloud_centers:\n",
    "    sphere=patches.Circle((sphere_i[0],sphere_i[1]), \n",
    "        radius=r_sphere,facecolor='red',\n",
    "        edgecolor='k', alpha=0.5)\n",
    "    ax.add_patch(sphere)   \n",
    "\n",
    "plt.axis(\"equal\")\n",
    "#plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering algorithm with pbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get distance matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "for d in range(arr.shape[1]):\n",
    "    # find all 1-d distances\n",
    "    pd=pdist(arr[:,d].reshape(arr.shape[0],1))\n",
    "    # apply boundary conditions\n",
    "    pd[pd>box_lx*0.5]-=box_lx\n",
    "     \n",
    "    try:\n",
    "        # sum\n",
    "        total+=pd**2\n",
    "    except:\n",
    "        # or define the sum if not previously defined\n",
    "        total=pd**2\n",
    "# transform the condensed distance matrix...\n",
    "total=pl.sqrt(total)\n",
    "# ...into a square distance matrix\n",
    "square=squareform(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "treshold=0.6\n",
    "\n",
    "db=DBSCAN(eps=threshold, metric='precomputed').fit(square)\n",
    "plt.scatter(arr[:,0], arr[:,1],c=db.labels_,s=3, edgecolors='None')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate non convex hull for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphashape\n",
    "import matplotlib.pyplot as plt\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "alpha = 0.95 * alphashape.optimizealpha(arr)\n",
    "hull = alphashape.alphashape(points, alpha)\n",
    "hull_pts = hull.exterior.coords.xy\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(hull_pts[0], hull_pts[1], color='red')\n",
    "ax.add_patch(PolygonPatch(hull, fill=False, color='green'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
